{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Fire Predictive Analytics with AWS SageMaker\n",
    "\n",
    "- This notebook details the training and deployment of a machine learning model on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn import tree, preprocessing\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# Now let's define the S3 bucket we'll used for the remainder of this example.\n",
    "\n",
    "# bucket = '' #  enter your s3 bucket where you will copy data and model artificats\n",
    "# prefix = 'sagemaker/DEMO-xgboost'  # place to upload training files within the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_data = \"path/from/s3/processed/data/from/aws/glue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "bucket='your/bucket/name'\n",
    "data_key = 'the/etl/output/train/data'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['discovery_date'] - pd.Timestamp(0).to_julian_date(), unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MONTH'] = pd.DatetimeIndex(df['DATE']).month\n",
    "df['DAY_OF_WEEK'] = df['DATE'].dt.weekday_name\n",
    "df_orig = df.copy() #I will use this copy later\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# df['STAT_CAUSE_DESCR'] = le.fit_transform(df['stat_cause_descr'])\n",
    "df['STATE'] = le.fit_transform(df['state'])\n",
    "df['DAY_OF_WEEK'] = le.fit_transform(df['DAY_OF_WEEK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_label(cat):\n",
    "    cause = 0\n",
    "    natural = ['Lightning']\n",
    "    accidental = ['Structure','Fireworks','Powerline','Railroad','Smoking',\n",
    "                  'Children','Campfire','Equipment Use','Debris Burning']\n",
    "    malicious = ['Arson']\n",
    "    other = ['Missing/Undefined','Miscellaneous']\n",
    "    if cat in natural:\n",
    "        cause = 1\n",
    "    elif cat in accidental:\n",
    "        cause = 2\n",
    "    elif cat in malicious:\n",
    "        cause = 3\n",
    "    else:\n",
    "        cause = 4\n",
    "    return cause\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LABEL'] = df['stat_cause_descr'].apply(lambda x: set_label(x)) # I created a copy of the original df earlier in the kernel\n",
    "df = df.drop('stat_cause_descr',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['state', 'fire_size_class', 'discovery_date', 'cont_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('DATE',axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing Model with SageMaker SKLearn Estimator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'aws_forest_wildfire_analytics.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.m5.large\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model, Run Predictions, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code for getting test values\n",
    "\n",
    "# Read Test data\n",
    "bucket='your/bucket/name'\n",
    "data_key = 'the/etl/output/test/set'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "print(data_location)\n",
    "\n",
    "test_df = pd.read_csv(data_location)\n",
    "test_df_orig = test_df.copy()\n",
    "test_df['DATE'] = pd.to_datetime(test_df['discovery_date'] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "test_df['MONTH'] = pd.DatetimeIndex(test_df['DATE']).month\n",
    "test_df['DAY_OF_WEEK'] = test_df['DATE'].dt.weekday_name\n",
    "le = preprocessing.LabelEncoder()\n",
    "test_df['STATE'] = le.fit_transform(test_df['state'])\n",
    "test_df['DAY_OF_WEEK'] = le.fit_transform(test_df['DAY_OF_WEEK'])\n",
    "\n",
    "def set_label(cat):\n",
    "    cause = 0\n",
    "    natural = ['Lightning']\n",
    "    accidental = ['Structure','Fireworks','Powerline','Railroad','Smoking',\n",
    "                  'Children','Campfire','Equipment Use','Debris Burning']\n",
    "    malicious = ['Arson']\n",
    "    other = ['Missing/Undefined','Miscellaneous']\n",
    "    if cat in natural:\n",
    "        cause = 1\n",
    "    elif cat in accidental:\n",
    "        cause = 2\n",
    "    elif cat in malicious:\n",
    "        cause = 3\n",
    "    else:\n",
    "        cause = 4\n",
    "    return cause\n",
    "     \n",
    "\n",
    "test_df['LABEL'] = test_df['stat_cause_descr'].apply(lambda x: set_label(x)) # I created a copy of the original test_df earlier in the kernel\n",
    "test_df = test_df.drop('stat_cause_descr',axis=1)\n",
    "test_df.drop(['state', 'fire_size_class', 'discovery_date', 'DATE', 'cont_date'], axis=1, inplace=True)\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "test_X = test_df.drop(['LABEL'], axis=1).values\n",
    "test_y = test_df['LABEL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = predictor.predict(test_X)\n",
    "y_true = test_y\n",
    "\n",
    "print(predictor.predict(test_X))\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_preds)\n",
    "\n",
    "print(\"Accuracy on test set: {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
